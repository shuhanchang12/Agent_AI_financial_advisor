# ğŸ“Š Multi-Agent Financial Research & Analysis â€” README

This repository contains a production-oriented multi-agent system for financial research and analysis. The system combines a TypeScript React frontend with a Python backend that uses LangGraph to orchestrate multiple specialized AI agents. It includes vector retrieval (Chroma), real-time web search (Tavily), human-in-the-loop approval, persistent state via SQLite, and observability through Langfuse.

## ğŸ“š Table of Contents

- [Features](#features)
- [Architecture](#architecture)
- [Quickstart](#quickstart)
- [Project Layout](#project-layout)
- [Observability & Persistence](#observability--persistence)
- [Notes](#notes)
- [License](#license)

Key highlights:

- Multi-agent workflow driven by LangGraph
- Retrieval-Augmented Generation (RAG) with Chroma vector database
- External web search using the Tavily API (with citations)
- Human-in-the-loop review and approval nodes
- Session/state persistence via SQLite
- Monitoring and tracing via Langfuse

<a id="features"></a>
## ğŸ§© Features

- Planner Agent: analyzes incoming queries and builds a research plan.
- Retrieval Agent: semantic search against the Chroma knowledge base.
- Web Search Agent: fetches up-to-date information using Tavily.
- Technical, Macro, and Sentiment Analysts: produce specialized insights.
- Writer Agent and Critic Agent: synthesize and refine final reports.
- Human Review Node: pauses workflow for human approval before finalizing.
- Langfuse integration for observability (traces, spans, metrics).

<a id="architecture"></a>
## ğŸ—ï¸ Architecture â€” Boxed Workflow Diagram

The diagram below uses square boxes to show the main program workflow and side services.

```
+------------------------------+
| Frontend (React / TypeScript) ğŸ–¥ï¸ |
+------------------------------+
		 |
		 v
+------------------------------+
| Backend API (FastAPI) âš™ï¸     |
+------------------------------+
		 |
		 v
+------------------------------+
| LangGraph Orchestrator ğŸ”     |
+------------------------------+
	|            |           
	v            v           v
+-------------+ +-------------+ +-------------+
| Retrieval   | | Web Search  | | Analysis    |
| (Chroma) ğŸ” | | (Tavily) ğŸŒ | | Agents ğŸ§    |
+-------------+ +-------------+ +-------------+
			 |
			 v
+------------------------------+
| Writer âœï¸  -> Critic ğŸ›¡ï¸      |
+------------------------------+
		 |
		 v
+------------------------------+
| Human Review (pause & action) ğŸ‘¥ |
+------------------------------+
		 |
		 v
+------------------------------+
| Persist (SQLite) ğŸ’¾          |
+------------------------------+

Side services: Langfuse (observability) ğŸ“Š, Logs ğŸ“
```

If you prefer, I can also add a Mermaid diagram or generate a PNG/SVG version of this boxed diagram and include it in the repo.

<a id="quickstart"></a>
## ğŸš€ Quickstart

Prerequisites:

- Python 3.9+
- Node.js 18+
- API keys: OpenAI, Tavily, Langfuse (optional for telemetry)

1. Clone the repository

```bash
git clone https://github.com/shuhanchang12/Agent_AI_financial_advisor.git
cd Agent_AI_financial_advisor/final_ai_trading_copilot
```

2. Install backend dependencies

```bash
cd backend
pip install -r requirements.txt
```

3. Install frontend dependencies

```bash
cd ../
npm install
```

4. Add environment variables

Create `backend/.env` (or set system env variables):

```env
OPENAI_API_KEY=your_openai_api_key
TAVILY_API_KEY=your_tavily_api_key
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
LANGFUSE_SECRET_KEY=your_langfuse_secret_key
LANGFUSE_HOST=https://cloud.langfuse.com
```

5. Initialize (if applicable)

```bash
python3 backend/init_system.py
```

6. Start services

Backend (API):

```bash
cd backend
python3 main.py
```

Frontend (development server):

```bash
cd ../
npm run dev
```

Default access points:

- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API docs (FastAPI): http://localhost:8000/docs

<a id="project-layout"></a>
## ğŸ—‚ï¸ Project Layout

- `backend/` â€” Python backend (FastAPI, LangGraph orchestration, agents)
- `src/` â€” React + TypeScript frontend
- `package.json`, `vite.config.ts` â€” frontend build configuration
- `Dockerfile.*`, `docker-compose.yml` â€” containerization and deployment

### Project Structure (current folder tree)

```
final_ai_trading_copilot/
â”œâ”€ .dockerignore
â”œâ”€ .gitignore
â”œâ”€ DEPLOYMENT_GUIDE.md
â”œâ”€ Dockerfile.backend
â”œâ”€ Dockerfile.frontend
â”œâ”€ PRESENTATION_10MIN_3PEOPLE.md
â”œâ”€ Proof Alpha Vantage API Connexion (Stock Price).png
â”œâ”€ Proof Back end Deployment.png
â”œâ”€ Proof Front end Deployment.png
â”œâ”€ Proof LangFuse.mov
â”œâ”€ Proof UI.mov
â”œâ”€ README.docx
â”œâ”€ README.md
â”œâ”€ backend/
â”‚  â”œâ”€ agent.py
â”‚  â”œâ”€ main.py
â”‚  â””â”€ requirements.txt
â”œâ”€ docker-compose.yml
â”œâ”€ index.css
â”œâ”€ index.html
â”œâ”€ package-lock.json
â”œâ”€ package.json
â”œâ”€ render.yaml
â”œâ”€ src/
â”‚  â”œâ”€ App.tsx
â”‚  â”œâ”€ components/
â”‚  â”‚  â”œâ”€ ChatInterface.tsx
â”‚  â”‚  â””â”€ MarketHeader.tsx
â”‚  â”œâ”€ index.css
â”‚  â”œâ”€ index.tsx
â”‚  â”œâ”€ services/
â”‚  â”‚  â””â”€ geminiService.ts
â”‚  â””â”€ types.ts
â”œâ”€ tsconfig.json
â”œâ”€ vercel.json
â””â”€ vite.config.ts
```

This tree reflects the repository contents in the `final_ai_trading_copilot` folder at the time of editing. Let me know if you want this expanded to include file descriptions or links to key files.

<a id="observability--persistence"></a>
## ğŸ”ğŸ’¾ Observability & Persistence

- State is stored in SQLite for session persistence and reproducibility.
- Langfuse is used to collect traces and metrics for each agent execution.

<a id="notes"></a>
## â„¹ï¸ Notes

- Tavily provides web search results and citations. Be mindful of rate limits and API usage quotas.
- Langfuse keys are optional but recommended for production observability.

<a id="license"></a>
## ğŸ“œ License

This project is provided for academic and demonstration purposes. Review the original repository license for reuse terms.

---
If you need the README tailored for a specific audience (developer, instructor, or deployer), tell me which audience and I'll produce a variant.
